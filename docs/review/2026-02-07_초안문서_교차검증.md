# 교차검증: 프로젝트 초안 문서 리뷰

- 날짜: 2026-02-07
- 검증 대상: README.md, CLAUDE.md, CROSS_VALIDATION_GUIDE.md (v1.0 초안)
- 사용 도구: ChatGPT, Perplexity

## 검증 내용
프로젝트 초안 3개 문서의 설계 완성도, 누락 항목, 실행 리스크를 교차검증

## 불일치/보완 항목

| # | 항목 | 원본 | ChatGPT 피드백 | Perplexity 피드백 | 반영 결과 |
|---|------|------|---------------|-----------------|----------|
| 1 | Hard Stop "상가 임차 다수" | 그대로 REJECT | 꼬마빌딩은 임차 다수가 기본값, 과도한 REJECT 발생 → 분쟁 시그널 중심으로 재정의 | - | ✅ HS-004를 "정보 결손 + 분쟁 정황"으로 재정의 |
| 2 | Hard Stop 0% 측정 기준 | 정의 없음 | 정답 라벨 없으면 측정 불가 → hard_stop_labels.json 필요 | Hard Stop 조건을 필드 레벨로 구체화 | ✅ 라벨 기준 명문화 + 필드 레벨 조건 추가 |
| 3 | 수집 비용 최적화 | 전 건 등기부 열람 | 2단 파이프라인 제안 (무료 1차 → 유료 2차) | - | ✅ CostGate 모듈 + 2단 구조 반영 |
| 4 | DB rights 모델 | priority INT만 존재 | accepted_at, registration_seq, registry_section, raw_text 추가 필요 | - | ✅ 4개 컬럼 추가 + analyses에 base_right_id 추가 |
| 5 | LLM 금지문구 처리 | 발견 시 삭제 | 삭제는 문맥 깨짐 → 재작성(Rewrite) 방식 | banned_phrases.json 분리 제안 | ✅ 재작성 프롬프트 + config 파일 분리 |
| 6 | 데이터 모델 정의 | 없음 | - | Auction, RuleResult 등 필수 필드 정의 필요 | ✅ CLAUDE.md에 전체 데이터 모델 추가 |
| 7 | API JSON 예시 | 없음 | - | 요청/응답 JSON 예시 추가 필요 | ✅ README에 2개 엔드포인트 예시 추가 |
| 8 | 교차검증 기록 | 기록 규칙 없음 | - | docs/review/ 에 마크다운으로 남기는 규칙 추가 | ✅ 템플릿 + 규칙 추가 |
| 9 | 사용자 페르소나 | 없음 | - | 페르소나 2~3개 + 시나리오 추가 | ✅ 3개 페르소나 + 시나리오 추가 |

## 결론
ChatGPT는 도메인 실무 관점(꼬마빌딩 특성, DB 모델링, 법적 리스크)에서 날카로운 피드백을 줌.
Perplexity는 개발자 관점(데이터 모델 명세, API 예시, 문서 관리 체계)에서 구조적 피드백을 줌.
두 도구의 피드백이 겹치지 않고 상호보완적이었으므로, 앞으로도 주요 설계 결정 시 양쪽 교차검증을 유지한다.
